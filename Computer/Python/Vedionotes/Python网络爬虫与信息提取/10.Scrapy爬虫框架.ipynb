{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy爬虫框架\n",
    "\n",
    "- 5+2结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据流"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 Engine从Spider处获得爬取请求(Request)\n",
    "- 2 Engine将爬取请求转发给Scheduler，用于调度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 Engine从Scheduler处获得下一个要爬取的请求\n",
    "- 4 Engine将爬取请求通过中间件发送给Downloader\n",
    "- 5 爬取网页后，Downloader形成响应（Response）通过中间件发给Engine\n",
    "- 6 Engine将收到的响应通过中间件发送给Spider处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 7 Spider处理响应后产生爬取项（scraped Item）和新的爬取请求（Requests）给Engine\n",
    "- 8 Engine将爬取项发送给Item Pipeline（框架出口）\n",
    "- 9 Engine将爬取请求发送给Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine\n",
    "- (1) 控制所有模块之间的数据流\n",
    "- (2) 根据条件触发事件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloader\n",
    "- 根据请求下载网页"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler\n",
    "- 对所有爬取请求进行调度管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloader Middleware\n",
    "\n",
    "- 目的：实施Engine、Scheduler和Downloader之间进行用户可配置的控制\n",
    "- 功能：修改、丢弃、新增请求或响应"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Spider\n",
    "- (1) 解析Downloader返回的响应（Response）\n",
    "- (2) 产生爬取项（scraped item）\n",
    "- (3) 产生额外的爬取请求（Request）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Pipelines\n",
    "- (1) 以流水线方式处理Spider产生的爬取项\n",
    "- (2) 由一组操作顺序组成，类似流水线，每个操作是一个Item Pipeline类型\n",
    "- (3) 可能操作包括：清理、检验和查重爬取项中的HTML数据、将数据存储到数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spider Middleware\n",
    "- 目的：对请求和爬取项的再处理\n",
    "- 功能：修改、丢弃、新增请求或爬取项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests库和Scrapy爬虫比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相同点：\n",
    "- 两者都可以进行页面请求和爬取，Python爬虫的两个重要技术路线\n",
    "- 两者可用性都好，文档丰富，入门简单\n",
    "- 两者都没有处理js、提交表单、应对验证码等功能（可扩展）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Requests库  |  Scrapy|\n",
    "|:------:|:------|\n",
    "|页面级爬虫    |         网站级爬虫|\n",
    "|功能库        |     框架|\n",
    "|并发性考虑不足，性能较差  | 并发性好，性能较高|\n",
    "|重点在于页面下载   | 重点在于爬虫结构|\n",
    "|定制灵活  | 一般定制灵活，深度定制困难|\n",
    "|上手十分简单 |  入门稍难|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy爬虫命令\n",
    "\n",
    "- Scrapy是为持续运行设计的专业爬虫框架，提供操作的Scrapy命令行Win下，启动cmd控制台\n",
    "- `scrapy <command> [options] [args]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|命令| 说明 |格式|\n",
    "|:----:|:----|:----|\n",
    "|startproject |创建一个新工程 |`scrapy startproject <name> [dir]`|\n",
    "|genspider |创建一个爬虫 |`scrapy genspider [options] <name> <domain>`|\n",
    "|settings |获得爬虫配置信息 |`scrapy settings [options]`|\n",
    "|crawl |运行一个爬虫 |`scrapy crawl <spider>`|\n",
    "|list |列出工程中所有爬虫 |`scrapy list`|\n",
    "|shell |启动URL调试命令行| `scrapy shell [url]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装命令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cmd\n",
    "conda install scrapy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
