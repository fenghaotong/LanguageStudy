{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy爬虫基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 步骤1 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 建立一个Scrapy爬虫工程\n",
    "- 在cmd中输入命令 `scrsapy startproject python123demo` 生成一个框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 步骤2 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在工程中产生一个Scrapy爬虫\n",
    "- 命令\n",
    "```\n",
    "scrapy genspider demo python123.io\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 该命令作用：\n",
    "    - (1) 生成一个名称为demo的spider\n",
    "    - (2) 在spiders目录下增加代码文件demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 步骤3 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 修改demo.py文件\n",
    "- 配置产生的spider爬虫\n",
    "- 配置：\n",
    "    - （1）初始URL地址 \n",
    "    - （2）获取页面后的解析方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 步骤4 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 运行爬虫，获取网页\n",
    "- 命令\n",
    "```\n",
    "scrapy crawl demo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yield关键字的使用\n",
    "\n",
    "- 生成器\n",
    "- 生成器是一个不断产生值得函数\n",
    "> 包含yield关键字的函数是一个生成器    \n",
    "> 生成器每次产生一个值（yield语句），函数被冻结，被唤醒后再产生一个值生成器是一个不断产生值的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(n):\n",
    "    for i in range(n):\n",
    "        yield i**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  4  9  16  "
     ]
    }
   ],
   "source": [
    "for i in gen(5):\n",
    "    print(i, \" \", end = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 为什么使用生成器呢？ **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 生成器相比一次列出所有内容的优势\n",
    "    - 更节省存储空间\n",
    "    - 响应更迅速\n",
    "    - 使用更灵活"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrapy爬虫的基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  scrapy爬虫的使用步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 步骤1：创建一个工程和Spider模板\n",
    "- 步骤2：编写Spider\n",
    "- 步骤3：编写Item Pipeline\n",
    "- 步骤4：优化配置策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrapy爬虫的数据类型\n",
    "\n",
    "- request类\n",
    "- response类\n",
    "- Item类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Request类 **\n",
    "\n",
    "class scrapy.http.Request()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Request对象表示一个HTTP请求\n",
    "- 由Spider生成，由Downloader执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|属性或方法 |说明|\n",
    "|:----:|:---|\n",
    "|.url| Request对应的请求URL地址|\n",
    "|.method| 对应的请求方法，'GET' 'POST'等|\n",
    "|.headers| 字典类型风格的请求头|\n",
    "|.body |请求内容主体，字符串类型|\n",
    "|.meta |用户添加的扩展信息，在Scrapy内部模块间传递信息使用|\n",
    "|.copy() |复制该请求|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Response类 **   \n",
    "\n",
    "class scrapy.http.Response()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Response对象表示一个HTTP响应\n",
    "- 由Downloader生成，由Spider处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|属性或方法| 说明|\n",
    "|:----:|:----|\n",
    "|.url| Response对应的URL地址|\n",
    "|.status |HTTP状态码，默认是200|\n",
    "|.headers |Response对应的头部信息|\n",
    "|.body |Response对应的内容信息，字符串类型|\n",
    "|.flags| 一组标记|\n",
    "|.request |产生Response类型对应的Request对象|\n",
    "|.copy() |复制该响应|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Item类 **\n",
    "\n",
    "class scrapy.item.Item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Item对象表示一个从HTML页面中提取的信息内容\n",
    "- 由Spider生成，由Item Pipeline处理\n",
    "- Item类似字典类型，可以按照字典类型操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrapy爬虫提取信息的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy爬虫支持多种HTML信息提取方法：\n",
    "- Beautiful Soup\n",
    "- lxml\n",
    "- re\n",
    "- XPath Selector\n",
    "- CSS Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CSS Selector的基本使用 **\n",
    "\n",
    "```\n",
    "<HTML>.css('a::attr(href)').extract()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
